{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import a csv\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the directory to C:\\Users\\ual-laptop\\Desktop\\BI\\Project\n",
    "os.chdir('C:\\\\Users\\\\ual-laptop\\\\Desktop\\\\BI\\\\Project')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['REVIEW_ID', 'AIRLINE_NAME', 'OVERALL_RATING', 'REVIEW_TITLE',\n",
       "       'REVIEW_DATE', 'VERIFIED', 'REVIEW', 'AIRCRAFT', 'TYPE_OF_TRAVELLER',\n",
       "       'SEAT_TYPE', 'ROUTE', 'DATE_FLOWN', 'SEAT_COMFORT',\n",
       "       'CABIN_STAFF_SERVICE', 'FOOD_BEVERAGES', 'GROUND_SERVICE',\n",
       "       'INFLIGHT_ENTERTAINMENT', 'WIFI_CONNECTIVITY', 'VALUE_FOR_MONEY',\n",
       "       'RECOMMENDED', 'IATA_CODE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the CSV file into a DataFrame\n",
    "file_name = 'cleaned_Airline_review_Final.csv'\n",
    "df = pd.read_csv(file_name)\n",
    "\n",
    "# Step 2: Rename the columns\n",
    "df.columns = df.columns.str.upper().str.replace(' ', '_')\n",
    "\n",
    "# Step 3: Save the modified DataFrame back to the same CSV file\n",
    "df.to_csv(file_name, index=False)\n",
    "\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['FL_DATE', 'AIRLINE', 'AIRLINE_DOT', 'IATA_CODE', 'DOT_CODE',\n",
       "       'FL_NUMBER', 'ORIGIN', 'ORIGIN_CITY', 'DEST', 'CRS_DEP_TIME',\n",
       "       'DEP_TIME', 'DEP_DELAY', 'TAXI_OUT', 'WHEELS_OFF', 'WHEELS_ON',\n",
       "       'TAXI_IN', 'CRS_ARR_TIME', 'ARR_TIME', 'ARR_DELAY', 'CANCELLED',\n",
       "       'CANCELLATION_CODE', 'DIVERTED', 'CRS_ELAPSED_TIME', 'ELAPSED_TIME',\n",
       "       'AIR_TIME', 'DISTANCE', 'DELAY_DUE_CARRIER', 'DELAY_DUE_WEATHER',\n",
       "       'DELAY_DUE_NAS', 'DELAY_DUE_SECURITY', 'DELAY_DUE_LATE_AIRCRAFT',\n",
       "       'ORIGIN_STATE', 'DESTINATION_CITY', 'DESTINATION_STATE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the column names of the csv file and not of the dataframe\n",
    "df = pd.read_csv('random_cleaned_flights_sample_3m.csv')\n",
    "\n",
    "df.head(10)\n",
    "\n",
    "#view all 34 columnns\n",
    "df.columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRS_DEP_TIME</th>\n",
       "      <th>DEP_TIME</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>CRS_ARR_TIME</th>\n",
       "      <th>ARR_TIME</th>\n",
       "      <th>ARR_DELAY</th>\n",
       "      <th>CRS_ELAPSED_TIME</th>\n",
       "      <th>ELAPSED_TIME</th>\n",
       "      <th>AIR_TIME</th>\n",
       "      <th>WHEELS_OFF</th>\n",
       "      <th>WHEELS_ON</th>\n",
       "      <th>TAXI_IN</th>\n",
       "      <th>TAXI_OUT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1551</td>\n",
       "      <td>1558.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1830</td>\n",
       "      <td>1830.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>159</td>\n",
       "      <td>152.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1613.0</td>\n",
       "      <td>1822.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>800</td>\n",
       "      <td>755.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1100</td>\n",
       "      <td>1044.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>180</td>\n",
       "      <td>169.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>810.0</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2155</td>\n",
       "      <td>2151.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>2315</td>\n",
       "      <td>2304.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>80</td>\n",
       "      <td>73.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>2201.0</td>\n",
       "      <td>2300.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>550</td>\n",
       "      <td>546.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>924</td>\n",
       "      <td>907.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>154</td>\n",
       "      <td>141.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>557.0</td>\n",
       "      <td>859.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2049</td>\n",
       "      <td>2049.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>31.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>384</td>\n",
       "      <td>402.0</td>\n",
       "      <td>374.0</td>\n",
       "      <td>2110.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>650</td>\n",
       "      <td>640.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>851</td>\n",
       "      <td>846.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>181</td>\n",
       "      <td>186.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>655.0</td>\n",
       "      <td>841.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1430</td>\n",
       "      <td>1428.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1622</td>\n",
       "      <td>1611.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>232</td>\n",
       "      <td>223.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1443.0</td>\n",
       "      <td>1603.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>740</td>\n",
       "      <td>740.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1010</td>\n",
       "      <td>949.0</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>330</td>\n",
       "      <td>309.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>944.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1455</td>\n",
       "      <td>1455.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1955</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>180</td>\n",
       "      <td>171.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>1942.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1315</td>\n",
       "      <td>1304.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>1449</td>\n",
       "      <td>1422.0</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>94</td>\n",
       "      <td>78.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1317.0</td>\n",
       "      <td>1419.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CRS_DEP_TIME  DEP_TIME  DEP_DELAY  CRS_ARR_TIME  ARR_TIME  ARR_DELAY  \\\n",
       "0          1551    1558.0        7.0          1830    1830.0        0.0   \n",
       "1           800     755.0       -5.0          1100    1044.0      -16.0   \n",
       "2          2155    2151.0       -4.0          2315    2304.0      -11.0   \n",
       "3           550     546.0       -4.0           924     907.0      -17.0   \n",
       "4          2049    2049.0        0.0            13      31.0       18.0   \n",
       "5           650     640.0      -10.0           851     846.0       -5.0   \n",
       "6          1430    1428.0       -2.0          1622    1611.0      -11.0   \n",
       "7           740     740.0        0.0          1010     949.0      -21.0   \n",
       "8          1455    1455.0        0.0          1955    1946.0       -9.0   \n",
       "9          1315    1304.0      -11.0          1449    1422.0      -27.0   \n",
       "\n",
       "   CRS_ELAPSED_TIME  ELAPSED_TIME  AIR_TIME  WHEELS_OFF  WHEELS_ON  TAXI_IN  \\\n",
       "0               159         152.0     129.0      1613.0     1822.0      8.0   \n",
       "1               180         169.0     150.0       810.0     1040.0      4.0   \n",
       "2                80          73.0      59.0      2201.0     2300.0      4.0   \n",
       "3               154         141.0     122.0       557.0      859.0      8.0   \n",
       "4               384         402.0     374.0      2110.0       24.0      7.0   \n",
       "5               181         186.0     166.0       655.0      841.0      5.0   \n",
       "6               232         223.0     200.0      1443.0     1603.0      8.0   \n",
       "7               330         309.0     294.0       750.0      944.0      5.0   \n",
       "8               180         171.0     154.0      1508.0     1942.0      4.0   \n",
       "9                94          78.0      62.0      1317.0     1419.0      3.0   \n",
       "\n",
       "   TAXI_OUT  \n",
       "0      15.0  \n",
       "1      15.0  \n",
       "2      10.0  \n",
       "3      11.0  \n",
       "4      21.0  \n",
       "5      15.0  \n",
       "6      15.0  \n",
       "7      10.0  \n",
       "8      13.0  \n",
       "9      13.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 10 rows of these columns: 'CRS_DEP_TIME', 'DEP_TIME', 'DEP_DELAY', 'CRS_ARR_TIME', 'ARR_TIME', 'ARR_DELAY', 'CRS_ELAPSED_TIME', 'ELAPSED_TIME', 'AIR_TIME'\n",
    "df[['CRS_DEP_TIME', 'DEP_TIME', 'DEP_DELAY', 'CRS_ARR_TIME', 'ARR_TIME', 'ARR_DELAY', 'CRS_ELAPSED_TIME', 'ELAPSED_TIME', 'AIR_TIME', 'WHEELS_OFF', 'WHEELS_ON', 'TAXI_IN','TAXI_OUT',]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct values of 'ORIGIN': 319\n",
      "Distinct values of 'DEST': 315\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('random_cleaned_flights_sample_3m.csv')\n",
    "\n",
    "# Count the distinct values of 'ORIGIN' and 'DEST'\n",
    "distinct_origin_values = df['ORIGIN'].nunique()\n",
    "distinct_dest_values = df['DEST'].nunique()\n",
    "\n",
    "# Display the counts\n",
    "print(\"Distinct values of 'ORIGIN':\", distinct_origin_values)\n",
    "print(\"Distinct values of 'DEST':\", distinct_dest_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Code                                               Name  \\\n",
      "0    BHM     BirminghamShuttlesworth International Airport   \n",
      "1    DHN                            Dothan Regional Airport   \n",
      "2    HSV  Huntsville International Airport (Carl T. Jone...   \n",
      "3    MOB                            Mobile Regional Airport   \n",
      "4    MGM       Montgomery Regional Airport (Dannelly Field)   \n",
      "..   ...                                                ...   \n",
      "374  BQN                           Rafael Hernández Airport   \n",
      "377  PSE                                  Mercedita Airport   \n",
      "379  SJU             Luis Muñoz Marín International Airport   \n",
      "381  STT                              Cyril E. King Airport   \n",
      "382  STX                           Henry E. Rohlsen Airport   \n",
      "\n",
      "                             City  \n",
      "0                      Birmingham  \n",
      "1                          Dothan  \n",
      "2                      Huntsville  \n",
      "3                          Mobile  \n",
      "4                      Montgomery  \n",
      "..                            ...  \n",
      "374                     Aguadilla  \n",
      "377                         Ponce  \n",
      "379           San Juan / Carolina  \n",
      "381  Charlotte Amalie, St. Thomas  \n",
      "382      Christiansted, St. Croix  \n",
      "\n",
      "[349 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Specify the path to your CSV file\n",
    "csv_file_path = 'All_Airports.csv'\n",
    "\n",
    "try:\n",
    "    # Try reading the CSV with UTF-8 encoding (default)\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "except UnicodeDecodeError:\n",
    "    try:\n",
    "        # If UTF-8 doesn't work, try reading with ISO-8859-1\n",
    "        df = pd.read_csv(csv_file_path, encoding='ISO-8859-1')\n",
    "    except UnicodeDecodeError:\n",
    "        # If ISO-8859-1 doesn't work, try reading with cp1252\n",
    "        df = pd.read_csv(csv_file_path, encoding='cp1252')\n",
    "\n",
    "# List of airport codes for which you want to extract details\n",
    "airport_codes = ['ABE','ABI','ABQ','ABR','ABY','ACK','ACT','ACV','ACY','ADK','ADQ','AEX','AGS','AKN','ALB','ALO','ALS','ALW','AMA','ANC','APN','ART','ASE','ATL','ATW','ATY','AUS','AVL','AVP','AZA','AZO','BDL','BET','BFF','BFL','BFM','BGM','BGR','BHM','BIH','BIL','BIS','BJI','BKG','BLI','BLV','BMI','BNA','BOI','BOS','BPT','BQK','BQN','BRD','BRO','BRW','BTM','BTR','BTV','BUF','BUR','BWI','BZN','CAE','CAK','CDB','CDC','CDV','CGI','CHA','CHO','CHS','CID','CIU','CKB','CLE','CLL','CLT','CMH','CMI','CMX','CNY','COD','COS','COU','CPR','CRP','CRW','CSG','CVG','CWA','CYS','DAB','DAL','DAY','DBQ','DCA','DDC','DEC','DEN','DFW','DHN','DIK','DLG','DLH','DRO','DRT','DSM','DTW','DVL','EAR','EAT','EAU','ECP','EGE','EKO','ELM','ELP','ERI','ESC','EUG','EVV','EWN','EWR','EYW','FAI','FAR','FAT','FAY','FCA','FLG','FLL','FLO','FNT','FOD','FSD','FSM','FWA','GCC','GCK','GEG','GFK','GGG','GJT','GNV','GPT','GRB','GRI','GRK','GRR','GSO','GSP','GST','GTF','GTR','GUC','GUM','HDN','HGR','HHH','HIB','HLN','HNL','HOB','HOU','HPN','HRL','HSV','HTS','HVN','HYA','HYS','IAD','IAG','IAH','ICT','IDA','ILG','ILM','IMT','IND','INL','IPT','ISN','ISP','ITH','ITO','JAC','JAN','JAX','JFK','JLN','JMS','JNU','JST','KOA','KTN','LAN','LAR','LAS','LAW','LAX','LBB','LBE','LBF','LBL','LCH','LCK','LEX','LFT','LGA','LGB','LIH','LIT','LNK','LRD','LSE','LWB','LWS','LYH','MAF','MBS','MCI','MCO','MCW','MDT','MDW','MEI','MEM','MFE','MFR','MGM','MHK','MHT','MIA','MKE','MKG','MLB','MLI','MLU','MMH','MOB','MOT','MQT','MRY','MSN','MSO','MSP','MSY','MTJ','MVY','MYR','OAJ','OAK','OGD','OGG','OGS','OKC','OMA','OME','ONT','ORD','ORF','ORH','OTH','OTZ','OWB','PAE','PAH','PBG','PBI','PDX','PGD','PGV','PHF','PHL','PHX','PIA','PIB','PIE','PIH','PIR','PIT','PLN','PNS','PPG','PRC','PSC','PSE','PSG','PSM','PSP','PUB','PUW','PVD','PVU','PWM','RAP','RDD','RDM','RDU','RFD','RHI','RIC','RIW','RKS','RNO','ROA','ROC','ROW','RST','RSW','SAF','SAN','SAT','SAV','SBA','SBN','SBP','SCC','SCE','SCK','SDF','SEA','SFB','SFO','SGF','SGU','SHD','SHR','SHV','SIT','SJC','SJT','SJU','SLC','SLN','SMF','SMX','SNA','SPI','SPN','SPS','SRQ','STC','STL','STS','STT','STX','SUN','SUX','SWF','SWO','SYR','TBN','TLH','TOL','TPA','TRI','TTN','TUL','TUS','TVC','TWF','TXK','TYR','TYS','UIN','USA','VCT','VEL','VLD','VPS','WRG','WYS','XNA','XWA','YAK','YKM','YUM']  # Replace with your actual codes\n",
    "\n",
    "# Extracting the details of the specified airports\n",
    "filtered_airports = df[df['Code'].isin(airport_codes)]\n",
    "\n",
    "# Displaying the details of the specified airports\n",
    "print(filtered_airports)\n",
    "\n",
    "# Save the details of the specified airports to a new CSV file\n",
    "filtered_airports.to_csv('filtered_airports.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elements not common in both lists: ['SPN', 'CGI', 'INL', 'DEC', 'CYS', 'PUB', 'MCW', 'ISN', 'BIH', 'VCT', 'UIN', 'BKG', 'CDB', 'DDC', 'BFM', 'HHH', 'FOD', 'ADK', 'LBL', 'USA', 'FCA', 'MQT', 'AZA', 'DVL', 'VEL', 'JST', 'IPT', 'PPG', 'MMH', 'SCE', 'YUM']\n"
     ]
    }
   ],
   "source": [
    "# Sample lists (replace these with your actual lists)\n",
    "list1 = ['ABE','ABI','ABQ','ABR','ABY','ACK','ACT','ACV','ACY','ADK','ADQ','AEX','AGS','AKN','ALB','ALO','ALS','ALW','AMA','ANC','APN','ART','ASE','ATL','ATW','ATY','AUS','AVL','AVP','AZA','AZO','BDL','BET','BFF','BFL','BFM','BGM','BGR','BHM','BIH','BIL','BIS','BJI','BKG','BLI','BLV','BMI','BNA','BOI','BOS','BPT','BQK','BQN','BRD','BRO','BRW','BTM','BTR','BTV','BUF','BUR','BWI','BZN','CAE','CAK','CDB','CDC','CDV','CGI','CHA','CHO','CHS','CID','CIU','CKB','CLE','CLL','CLT','CMH','CMI','CMX','CNY','COD','COS','COU','CPR','CRP','CRW','CSG','CVG','CWA','CYS','DAB','DAL','DAY','DBQ','DCA','DDC','DEC','DEN','DFW','DHN','DIK','DLG','DLH','DRO','DRT','DSM','DTW','DVL','EAR','EAT','EAU','ECP','EGE','EKO','ELM','ELP','ERI','ESC','EUG','EVV','EWN','EWR','EYW','FAI','FAR','FAT','FAY','FCA','FLG','FLL','FLO','FNT','FOD','FSD','FSM','FWA','GCC','GCK','GEG','GFK','GGG','GJT','GNV','GPT','GRB','GRI','GRK','GRR','GSO','GSP','GST','GTF','GTR','GUC','GUM','HDN','HGR','HHH','HIB','HLN','HNL','HOB','HOU','HPN','HRL','HSV','HTS','HVN','HYA','HYS','IAD','IAG','IAH','ICT','IDA','ILG','ILM','IMT','IND','INL','IPT','ISN','ISP','ITH','ITO','JAC','JAN','JAX','JFK','JLN','JMS','JNU','JST','KOA','KTN','LAN','LAR','LAS','LAW','LAX','LBB','LBE','LBF','LBL','LCH','LCK','LEX','LFT','LGA','LGB','LIH','LIT','LNK','LRD','LSE','LWB','LWS','LYH','MAF','MBS','MCI','MCO','MCW','MDT','MDW','MEI','MEM','MFE','MFR','MGM','MHK','MHT','MIA','MKE','MKG','MLB','MLI','MLU','MMH','MOB','MOT','MQT','MRY','MSN','MSO','MSP','MSY','MTJ','MVY','MYR','OAJ','OAK','OGD','OGG','OGS','OKC','OMA','OME','ONT','ORD','ORF','ORH','OTH','OTZ','OWB','PAE','PAH','PBG','PBI','PDX','PGD','PGV','PHF','PHL','PHX','PIA','PIB','PIE','PIH','PIR','PIT','PLN','PNS','PPG','PRC','PSC','PSE','PSG','PSM','PSP','PUB','PUW','PVD','PVU','PWM','RAP','RDD','RDM','RDU','RFD','RHI','RIC','RIW','RKS','RNO','ROA','ROC','ROW','RST','RSW','SAF','SAN','SAT','SAV','SBA','SBN','SBP','SCC','SCE','SCK','SDF','SEA','SFB','SFO','SGF','SGU','SHD','SHR','SHV','SIT','SJC','SJT','SJU','SLC','SLN','SMF','SMX','SNA','SPI','SPN','SPS','SRQ','STC','STL','STS','STT','STX','SUN','SUX','SWF','SWO','SYR','TBN','TLH','TOL','TPA','TRI','TTN','TUL','TUS','TVC','TWF','TXK','TYR','TYS','UIN','USA','VCT','VEL','VLD','VPS','WRG','WYS','XNA','XWA','YAK','YKM','YUM']\n",
    "list2 = ['BHM','DHN','HSV','MOB','MGM','ANC','BET','CDV','SCC','DLG','FAI','GST','JNU','KTN','AKN','ADQ','OTZ','OME','PSG','SIT','BRW','WRG','YAK','FLG','PHX','PRC','TUS','XNA','FSM','LIT','TXK','ACV','BFL','BUR','FAT','LGB','LAX','MRY','OAK','ONT','SNA','PSP','RDD','SMF','SAN','SFO','SJC','SBP','SBA','SMX','STS','SCK','ALS','ASE','COS','DEN','DRO','EGE','GJT','GUC','HDN','MTJ','BDL','HVN','ILG','DAB','FLL','RSW','VPS','GNV','JAX','EYW','MLB','MIA','MCO','ECP','PNS','PGD','SFB','SRQ','PIE','TLH','TPA','PBI','ABY','ATL','AGS','BQK','CSG','SAV','VLD','ITO','HNL','OGG','KOA','LIH','BOI','SUN','IDA','LWS','PIH','TWF','BLV','BMI','CMI','MDW','ORD','MLI','PIA','RFD','SPI','EVV','FWA','IND','SBN','CID','DSM','DBQ','SUX','ALO','GCK','HYS','MHK','SLN','ICT','CVG','LEX','SDF','OWB','PAH','AEX','BTR','LFT','LCH','MLU','MSY','SHV','BGR','PWM','BWI','HGR','BOS','HYA','ACK','MVY','ORH','APN','DTW','ESC','FNT','GRR','CMX','IMT','AZO','LAN','MKG','PLN','MBS','CIU','TVC','BJI','BRD','DLH','HIB','MSP','RST','STC','GTR','GPT','PIB','JAN','MEI','COU','TBN','JLN','MCI','STL','SGF','BIL','BZN','BTM','GTF','HLN','MSO','WYS','GRI','EAR','LNK','LBF','OMA','BFF','EKO','LAS','RNO','MHT','PSM','ACY','EWR','TTN','ABQ','HOB','ROW','SAF','ALB','BGM','BUF','ELM','ITH','JFK','LGA','ISP','SWF','IAG','OGS','PBG','ROC','SYR','ART','HPN','AVL','CLT','FAY','GSO','PGV','OAJ','EWN','RDU','ILM','BIS','DIK','FAR','GFK','JMS','MOT','XWA','CAK','CLE','CMH','LCK','DAY','TOL','LAW','OKC','SWO','TUL','EUG','MFR','OTH','PDX','RDM','ABE','ERI','MDT','LBE','PHL','PIT','AVP','PVD','CHS','CAE','FLO','GSP','MYR','ABR','PIR','RAP','FSD','ATY','CHA','TYS','MEM','BNA','TRI','ABI','AMA','AUS','BPT','BRO','CLL','CRP','DAL','DFW','DRT','ELP','HRL','IAH','HOU','GRK','LRD','GGG','LBB','MFE','MAF','SJT','SAT','TYR','ACT','SPS','CDC','CNY','OGD','PVU','SGU','SLC','BTV','CHO','LYH','PHF','ORF','RIC','ROA','SHD','DCA','IAD','BLI','PAE','PSC','PUW','SEA','GEG','ALW','EAT','YKM','CRW','CKB','HTS','LWB','ATW','EAU','GRB','LSE','MSN','MKE','CWA','RHI','CPR','COD','GCC','JAC','LAR','RIW','RKS','SHR','GUM','BQN','PSE','SJU','STT','STX']\n",
    "\n",
    "# Convert lists to sets\n",
    "set1 = set(list1)\n",
    "set2 = set(list2)\n",
    "\n",
    "# Find elements that are unique to each list\n",
    "unique_to_list1 = set1 - set2\n",
    "unique_to_list2 = set2 - set1\n",
    "\n",
    "# Combine the unique elements from both lists\n",
    "not_common_elements = unique_to_list1.union(unique_to_list2)\n",
    "\n",
    "# Convert the set back to a list, if you need it in list form\n",
    "not_common_elements_list = list(not_common_elements)\n",
    "\n",
    "# Display the result\n",
    "print(\"Elements not common in both lists:\", not_common_elements_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\ual-laptop\\anaconda3\\lib\\site-packages (3.0.10)\n",
      "Requirement already satisfied: et_xmlfile in c:\\users\\ual-laptop\\anaconda3\\lib\\site-packages (from openpyxl) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(\"review_source.csv\")\n",
    "\n",
    "# Function to convert text date to datetime format\n",
    "def convert_text_to_date(text_date):\n",
    "    # Remove any commas from the text date\n",
    "    text_date = text_date.replace(\",\", \"\")\n",
    "    \n",
    "    # Extract day, month, and year from the text date\n",
    "    day, month, year = text_date.split(\" \")\n",
    "\n",
    "    # Remove the suffix from the day\n",
    "    day = day[:-2]\n",
    "\n",
    "    # Convert month name to month number\n",
    "    month_number = datetime.strptime(month, \"%B\").month\n",
    "\n",
    "    # Create datetime object\n",
    "    date_obj = datetime(int(year), month_number, int(day))\n",
    "    \n",
    "    return date_obj.strftime(\"%m-%d-%Y\")\n",
    "\n",
    "# Apply the function to the \"Review Date\" column and store the result in a new column\n",
    "df[\"Review_Date\"] = df[\"Review Date\"].apply(convert_text_to_date)\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "df.to_csv(\"updated_review_source.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('random_cleaned_flights_sample_3m.csv')\n",
    "\n",
    "# Ensure the column data does not exceed 255 characters\n",
    "# Replace 'your_column_name' with the actual column name\n",
    "df['ORIGIN'] = df['ORIGIN'].astype(str).str.slice(0, 255)\n",
    "\n",
    "# Save the modified DataFrame back to a new CSV file if needed\n",
    "df.to_csv('new_random_cleaned_flights_sample_3m.csv', index=False)\n",
    "\n",
    "# If directly inserting into a database, proceed with the insertion\n",
    "# using the modified DataFrame. This will depend on your database system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(\n",
    "'cleaned_Airline_review_Final.csv')\n",
    "# Split the \"Route\" column into two columns\n",
    "df[['Route_Before', 'Route_After']] = df['ROUTE'].str.split(' to ', expand=True)\n",
    "\n",
    "# Save the updated DataFrame to the CSV file\n",
    "df.to_csv('cleaned_Airline_review_Final.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REVIEW_ID</th>\n",
       "      <th>AIRLINE_NAME</th>\n",
       "      <th>OVERALL_RATING</th>\n",
       "      <th>REVIEW_TITLE</th>\n",
       "      <th>REVIEW_DATE</th>\n",
       "      <th>VERIFIED</th>\n",
       "      <th>REVIEW</th>\n",
       "      <th>AIRCRAFT</th>\n",
       "      <th>TYPE_OF_TRAVELLER</th>\n",
       "      <th>SEAT_TYPE</th>\n",
       "      <th>...</th>\n",
       "      <th>CABIN_STAFF_SERVICE</th>\n",
       "      <th>FOOD_BEVERAGES</th>\n",
       "      <th>GROUND_SERVICE</th>\n",
       "      <th>INFLIGHT_ENTERTAINMENT</th>\n",
       "      <th>WIFI_CONNECTIVITY</th>\n",
       "      <th>VALUE_FOR_MONEY</th>\n",
       "      <th>RECOMMENDED</th>\n",
       "      <th>IATA_CODE</th>\n",
       "      <th>Route_Before</th>\n",
       "      <th>Route_After</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3801</td>\n",
       "      <td>Alaska Airlines</td>\n",
       "      <td>1</td>\n",
       "      <td>\"carpet was so dirty\"</td>\n",
       "      <td>24th July 2023</td>\n",
       "      <td>False</td>\n",
       "      <td>Never again! My ticket was messed up, I had t...</td>\n",
       "      <td>Boeing 737-800</td>\n",
       "      <td>Solo Leisure</td>\n",
       "      <td>First Class</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>AS</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>Seattle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3802</td>\n",
       "      <td>Alaska Airlines</td>\n",
       "      <td>1</td>\n",
       "      <td>\"have the audacity to be truthful\"</td>\n",
       "      <td>23rd July 2023</td>\n",
       "      <td>True</td>\n",
       "      <td>Booked a round trip with this company for a ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Family Leisure</td>\n",
       "      <td>Premium Economy</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>AS</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>Orlando</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3803</td>\n",
       "      <td>Alaska Airlines</td>\n",
       "      <td>2</td>\n",
       "      <td>\"a lot of shortfalls all over the place\"</td>\n",
       "      <td>22nd July 2023</td>\n",
       "      <td>True</td>\n",
       "      <td>No in flight entertainment. Inconvenient foo...</td>\n",
       "      <td>Boeing 737</td>\n",
       "      <td>Solo Leisure</td>\n",
       "      <td>First Class</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>AS</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>Detroit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3804</td>\n",
       "      <td>Alaska Airlines</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Absolutely terrible experience\"</td>\n",
       "      <td>22nd July 2023</td>\n",
       "      <td>True</td>\n",
       "      <td>Absolutely terrible experience flying with A...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Family Leisure</td>\n",
       "      <td>Premium Economy</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>AS</td>\n",
       "      <td>Austin</td>\n",
       "      <td>Seattle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3805</td>\n",
       "      <td>Alaska Airlines</td>\n",
       "      <td>1</td>\n",
       "      <td>\"the pilot had no sense of urgency\"</td>\n",
       "      <td>21st July 2023</td>\n",
       "      <td>True</td>\n",
       "      <td>We were on a connecting flight to London and ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Business</td>\n",
       "      <td>Business Class</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>AS</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>Seattle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   REVIEW_ID     AIRLINE_NAME OVERALL_RATING  \\\n",
       "0       3801  Alaska Airlines              1   \n",
       "1       3802  Alaska Airlines              1   \n",
       "2       3803  Alaska Airlines              2   \n",
       "3       3804  Alaska Airlines              1   \n",
       "4       3805  Alaska Airlines              1   \n",
       "\n",
       "                               REVIEW_TITLE     REVIEW_DATE  VERIFIED  \\\n",
       "0                     \"carpet was so dirty\"  24th July 2023     False   \n",
       "1        \"have the audacity to be truthful\"  23rd July 2023      True   \n",
       "2  \"a lot of shortfalls all over the place\"  22nd July 2023      True   \n",
       "3          \"Absolutely terrible experience\"  22nd July 2023      True   \n",
       "4       \"the pilot had no sense of urgency\"  21st July 2023      True   \n",
       "\n",
       "                                              REVIEW        AIRCRAFT  \\\n",
       "0   Never again! My ticket was messed up, I had t...  Boeing 737-800   \n",
       "1    Booked a round trip with this company for a ...             NaN   \n",
       "2    No in flight entertainment. Inconvenient foo...      Boeing 737   \n",
       "3    Absolutely terrible experience flying with A...             NaN   \n",
       "4   We were on a connecting flight to London and ...             NaN   \n",
       "\n",
       "  TYPE_OF_TRAVELLER        SEAT_TYPE  ... CABIN_STAFF_SERVICE FOOD_BEVERAGES  \\\n",
       "0      Solo Leisure      First Class  ...                 1.0            1.0   \n",
       "1    Family Leisure  Premium Economy  ...                 1.0            1.0   \n",
       "2      Solo Leisure      First Class  ...                 2.0            2.0   \n",
       "3    Family Leisure  Premium Economy  ...                 1.0            2.0   \n",
       "4          Business   Business Class  ...                 5.0            5.0   \n",
       "\n",
       "   GROUND_SERVICE  INFLIGHT_ENTERTAINMENT  WIFI_CONNECTIVITY  VALUE_FOR_MONEY  \\\n",
       "0             1.0                     1.0                1.0              1.0   \n",
       "1             1.0                     1.0                4.0              1.0   \n",
       "2             1.0                     1.0                1.0              2.0   \n",
       "3             1.0                     2.0                2.0              1.0   \n",
       "4             1.0                     NaN                NaN              1.0   \n",
       "\n",
       "   RECOMMENDED  IATA_CODE   Route_Before Route_After  \n",
       "0           no         AS         Dallas     Seattle  \n",
       "1           no         AS  San Francisco     Orlando  \n",
       "2           no         AS      Anchorage     Detroit  \n",
       "3           no         AS         Austin     Seattle  \n",
       "4           no         AS      San Diego     Seattle  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Route_After'] = df['Route_After'].str.split(' via').str[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the 'cleaned_Airline_review_Final.csv' file\n",
    "df_review = pd.read_csv('cleaned_Airline_review_Final.csv')\n",
    "\n",
    "# Read the 'All_Airports.csv' file\n",
    "df_airports = pd.read_csv('filtered_airports.csv')\n",
    "\n",
    "# Merge the two dataframes based on the City and Route_Before columns\n",
    "df_merged = pd.merge(df_review, df_airports, left_on='Route_Before', right_on='City', how='left')\n",
    "\n",
    "# Create a new column 'Airport_code' and insert the corresponding values\n",
    "df_merged['Airport Code'] = df_merged['Airport Code']\n",
    "\n",
    "# Save the updated dataframe to a new CSV file\n",
    "df_merged.to_csv('merged_review.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review = pd.read_csv('cleaned_Airline_review_Final.csv')\n",
    "\n",
    "# Read the filtered_airports.csv file\n",
    "df_airports = pd.read_csv('filtered_airports.csv')\n",
    "\n",
    "df['Route_After'] = df['Route_After'].str.split(' via').str[0]\n",
    "\n",
    "# Save the updated DataFrame to the CSV file\n",
    "df.to_csv('cleaned_Airline_review_Final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REVIEW_ID</th>\n",
       "      <th>AIRLINE_NAME</th>\n",
       "      <th>OVERALL_RATING</th>\n",
       "      <th>REVIEW_TITLE</th>\n",
       "      <th>REVIEW_DATE</th>\n",
       "      <th>VERIFIED</th>\n",
       "      <th>REVIEW</th>\n",
       "      <th>AIRCRAFT</th>\n",
       "      <th>TYPE_OF_TRAVELLER</th>\n",
       "      <th>SEAT_TYPE</th>\n",
       "      <th>...</th>\n",
       "      <th>VALUE_FOR_MONEY</th>\n",
       "      <th>RECOMMENDED</th>\n",
       "      <th>IATA_CODE</th>\n",
       "      <th>Route_Before</th>\n",
       "      <th>Route_After</th>\n",
       "      <th>Destination Airport Code</th>\n",
       "      <th>Airport Code</th>\n",
       "      <th>Airport Name</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3801</td>\n",
       "      <td>Alaska Airlines</td>\n",
       "      <td>1</td>\n",
       "      <td>\"carpet was so dirty\"</td>\n",
       "      <td>24th July 2023</td>\n",
       "      <td>False</td>\n",
       "      <td>Never again! My ticket was messed up, I had t...</td>\n",
       "      <td>Boeing 737-800</td>\n",
       "      <td>Solo Leisure</td>\n",
       "      <td>First Class</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>AS</td>\n",
       "      <td>Dallas/Fort Worth International</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>SEA</td>\n",
       "      <td>SEA</td>\n",
       "      <td>Seattle-Tacoma International</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3802</td>\n",
       "      <td>Alaska Airlines</td>\n",
       "      <td>1</td>\n",
       "      <td>\"have the audacity to be truthful\"</td>\n",
       "      <td>23rd July 2023</td>\n",
       "      <td>True</td>\n",
       "      <td>Booked a round trip with this company for a ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Family Leisure</td>\n",
       "      <td>Premium Economy</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>AS</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>Orlando</td>\n",
       "      <td>MCO</td>\n",
       "      <td>MCO</td>\n",
       "      <td>Orlando International</td>\n",
       "      <td>Orlando</td>\n",
       "      <td>FL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3803</td>\n",
       "      <td>Alaska Airlines</td>\n",
       "      <td>2</td>\n",
       "      <td>\"a lot of shortfalls all over the place\"</td>\n",
       "      <td>22nd July 2023</td>\n",
       "      <td>True</td>\n",
       "      <td>No in flight entertainment. Inconvenient foo...</td>\n",
       "      <td>Boeing 737</td>\n",
       "      <td>Solo Leisure</td>\n",
       "      <td>First Class</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>AS</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>Detroit</td>\n",
       "      <td>DTW</td>\n",
       "      <td>DTW</td>\n",
       "      <td>Detroit Metropolitan Wayne County</td>\n",
       "      <td>Detroit</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3804</td>\n",
       "      <td>Alaska Airlines</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Absolutely terrible experience\"</td>\n",
       "      <td>22nd July 2023</td>\n",
       "      <td>True</td>\n",
       "      <td>Absolutely terrible experience flying with A...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Family Leisure</td>\n",
       "      <td>Premium Economy</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>AS</td>\n",
       "      <td>Austin</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>SEA</td>\n",
       "      <td>SEA</td>\n",
       "      <td>Seattle-Tacoma International</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3805</td>\n",
       "      <td>Alaska Airlines</td>\n",
       "      <td>1</td>\n",
       "      <td>\"the pilot had no sense of urgency\"</td>\n",
       "      <td>21st July 2023</td>\n",
       "      <td>True</td>\n",
       "      <td>We were on a connecting flight to London and ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Business</td>\n",
       "      <td>Business Class</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>AS</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>SEA</td>\n",
       "      <td>SEA</td>\n",
       "      <td>Seattle-Tacoma International</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   REVIEW_ID     AIRLINE_NAME OVERALL_RATING  \\\n",
       "0       3801  Alaska Airlines              1   \n",
       "1       3802  Alaska Airlines              1   \n",
       "2       3803  Alaska Airlines              2   \n",
       "3       3804  Alaska Airlines              1   \n",
       "4       3805  Alaska Airlines              1   \n",
       "\n",
       "                               REVIEW_TITLE     REVIEW_DATE  VERIFIED  \\\n",
       "0                     \"carpet was so dirty\"  24th July 2023     False   \n",
       "1        \"have the audacity to be truthful\"  23rd July 2023      True   \n",
       "2  \"a lot of shortfalls all over the place\"  22nd July 2023      True   \n",
       "3          \"Absolutely terrible experience\"  22nd July 2023      True   \n",
       "4       \"the pilot had no sense of urgency\"  21st July 2023      True   \n",
       "\n",
       "                                              REVIEW        AIRCRAFT  \\\n",
       "0   Never again! My ticket was messed up, I had t...  Boeing 737-800   \n",
       "1    Booked a round trip with this company for a ...             NaN   \n",
       "2    No in flight entertainment. Inconvenient foo...      Boeing 737   \n",
       "3    Absolutely terrible experience flying with A...             NaN   \n",
       "4   We were on a connecting flight to London and ...             NaN   \n",
       "\n",
       "  TYPE_OF_TRAVELLER        SEAT_TYPE  ... VALUE_FOR_MONEY RECOMMENDED  \\\n",
       "0      Solo Leisure      First Class  ...             1.0          no   \n",
       "1    Family Leisure  Premium Economy  ...             1.0          no   \n",
       "2      Solo Leisure      First Class  ...             2.0          no   \n",
       "3    Family Leisure  Premium Economy  ...             1.0          no   \n",
       "4          Business   Business Class  ...             1.0          no   \n",
       "\n",
       "   IATA_CODE                     Route_Before  Route_After  \\\n",
       "0         AS  Dallas/Fort Worth International      Seattle   \n",
       "1         AS                    San Francisco      Orlando   \n",
       "2         AS                        Anchorage      Detroit   \n",
       "3         AS                           Austin      Seattle   \n",
       "4         AS                        San Diego      Seattle   \n",
       "\n",
       "   Destination Airport Code  Airport Code                       Airport Name  \\\n",
       "0                       SEA           SEA       Seattle-Tacoma International   \n",
       "1                       MCO           MCO              Orlando International   \n",
       "2                       DTW           DTW  Detroit Metropolitan Wayne County   \n",
       "3                       SEA           SEA       Seattle-Tacoma International   \n",
       "4                       SEA           SEA       Seattle-Tacoma International   \n",
       "\n",
       "      City State  \n",
       "0  Seattle    WA  \n",
       "1  Orlando    FL  \n",
       "2  Detroit    MI  \n",
       "3  Seattle    WA  \n",
       "4  Seattle    WA  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df = pd.read_csv('cleaned_Airline_review_Final.csv')\n",
    "cleaned_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the 'cleaned_Airline_review_Final.csv' file into a DataFrame\n",
    "cleaned_df = pd.read_csv('cleaned_Airline_review_Final.csv')\n",
    "cleaned_df.head()\n",
    "\n",
    "# Step 2: Load the 'filtered_airports.csv' file into another DataFrame\n",
    "filtered_airports_df = pd.read_csv('filtered_airports.csv')\n",
    "\n",
    "# Step 3: Merge the two DataFrames based on the 'City' column and the 'Route_Before' column\n",
    "merged_df = cleaned_df.merge(filtered_airports_df, left_on='Route_After', right_on='City', how='left')\n",
    "\n",
    "# Step 4: Extract the 'Airport Code' column from the merged DataFrame and assign it to a new column called 'Source Airport Code'\n",
    "merged_df['Destination Airport Code'] = merged_df['Airport Code']\n",
    "\n",
    "# Step 5: Save the modified DataFrame back to the 'cleaned_Airline_review_Final.csv' file\n",
    "merged_df.to_csv('cleaned_Airline_review_Final.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REVIEW_ID</th>\n",
       "      <th>AIRLINE_NAME</th>\n",
       "      <th>OVERALL_RATING</th>\n",
       "      <th>REVIEW_TITLE</th>\n",
       "      <th>REVIEW_DATE</th>\n",
       "      <th>VERIFIED</th>\n",
       "      <th>REVIEW</th>\n",
       "      <th>AIRCRAFT</th>\n",
       "      <th>TYPE_OF_TRAVELLER</th>\n",
       "      <th>SEAT_TYPE</th>\n",
       "      <th>...</th>\n",
       "      <th>VALUE_FOR_MONEY</th>\n",
       "      <th>RECOMMENDED</th>\n",
       "      <th>IATA_CODE</th>\n",
       "      <th>Route_Before</th>\n",
       "      <th>Route_After</th>\n",
       "      <th>Source Airport Code</th>\n",
       "      <th>Airport Code</th>\n",
       "      <th>Airport Name</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3801</td>\n",
       "      <td>Alaska Airlines</td>\n",
       "      <td>1</td>\n",
       "      <td>\"carpet was so dirty\"</td>\n",
       "      <td>24th July 2023</td>\n",
       "      <td>False</td>\n",
       "      <td>Never again! My ticket was messed up, I had t...</td>\n",
       "      <td>Boeing 737-800</td>\n",
       "      <td>Solo Leisure</td>\n",
       "      <td>First Class</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>AS</td>\n",
       "      <td>Dallas/Fort Worth</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>DFW</td>\n",
       "      <td>DFW</td>\n",
       "      <td>Dallas/Fort Worth International</td>\n",
       "      <td>Dallas/Fort Worth</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3802</td>\n",
       "      <td>Alaska Airlines</td>\n",
       "      <td>1</td>\n",
       "      <td>\"have the audacity to be truthful\"</td>\n",
       "      <td>23rd July 2023</td>\n",
       "      <td>True</td>\n",
       "      <td>Booked a round trip with this company for a ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Family Leisure</td>\n",
       "      <td>Premium Economy</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>AS</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>Orlando</td>\n",
       "      <td>SFO</td>\n",
       "      <td>SFO</td>\n",
       "      <td>San Francisco International</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3803</td>\n",
       "      <td>Alaska Airlines</td>\n",
       "      <td>2</td>\n",
       "      <td>\"a lot of shortfalls all over the place\"</td>\n",
       "      <td>22nd July 2023</td>\n",
       "      <td>True</td>\n",
       "      <td>No in flight entertainment. Inconvenient foo...</td>\n",
       "      <td>Boeing 737</td>\n",
       "      <td>Solo Leisure</td>\n",
       "      <td>First Class</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>AS</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>Detroit</td>\n",
       "      <td>ANC</td>\n",
       "      <td>ANC</td>\n",
       "      <td>Ted Stevens Anchorage</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3804</td>\n",
       "      <td>Alaska Airlines</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Absolutely terrible experience\"</td>\n",
       "      <td>22nd July 2023</td>\n",
       "      <td>True</td>\n",
       "      <td>Absolutely terrible experience flying with A...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Family Leisure</td>\n",
       "      <td>Premium Economy</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>AS</td>\n",
       "      <td>Austin</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>AUS</td>\n",
       "      <td>AUS</td>\n",
       "      <td>Austin-Bergstrom</td>\n",
       "      <td>Austin</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3805</td>\n",
       "      <td>Alaska Airlines</td>\n",
       "      <td>1</td>\n",
       "      <td>\"the pilot had no sense of urgency\"</td>\n",
       "      <td>21st July 2023</td>\n",
       "      <td>True</td>\n",
       "      <td>We were on a connecting flight to London and ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Business</td>\n",
       "      <td>Business Class</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>AS</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>SAN</td>\n",
       "      <td>SAN</td>\n",
       "      <td>San Diego International</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   REVIEW_ID     AIRLINE_NAME OVERALL_RATING  \\\n",
       "0       3801  Alaska Airlines              1   \n",
       "1       3802  Alaska Airlines              1   \n",
       "2       3803  Alaska Airlines              2   \n",
       "3       3804  Alaska Airlines              1   \n",
       "4       3805  Alaska Airlines              1   \n",
       "\n",
       "                               REVIEW_TITLE     REVIEW_DATE  VERIFIED  \\\n",
       "0                     \"carpet was so dirty\"  24th July 2023     False   \n",
       "1        \"have the audacity to be truthful\"  23rd July 2023      True   \n",
       "2  \"a lot of shortfalls all over the place\"  22nd July 2023      True   \n",
       "3          \"Absolutely terrible experience\"  22nd July 2023      True   \n",
       "4       \"the pilot had no sense of urgency\"  21st July 2023      True   \n",
       "\n",
       "                                              REVIEW        AIRCRAFT  \\\n",
       "0   Never again! My ticket was messed up, I had t...  Boeing 737-800   \n",
       "1    Booked a round trip with this company for a ...             NaN   \n",
       "2    No in flight entertainment. Inconvenient foo...      Boeing 737   \n",
       "3    Absolutely terrible experience flying with A...             NaN   \n",
       "4   We were on a connecting flight to London and ...             NaN   \n",
       "\n",
       "  TYPE_OF_TRAVELLER        SEAT_TYPE  ... VALUE_FOR_MONEY RECOMMENDED  \\\n",
       "0      Solo Leisure      First Class  ...             1.0          no   \n",
       "1    Family Leisure  Premium Economy  ...             1.0          no   \n",
       "2      Solo Leisure      First Class  ...             2.0          no   \n",
       "3    Family Leisure  Premium Economy  ...             1.0          no   \n",
       "4          Business   Business Class  ...             1.0          no   \n",
       "\n",
       "   IATA_CODE       Route_Before  Route_After  Source Airport Code  \\\n",
       "0         AS  Dallas/Fort Worth      Seattle                  DFW   \n",
       "1         AS      San Francisco      Orlando                  SFO   \n",
       "2         AS          Anchorage      Detroit                  ANC   \n",
       "3         AS             Austin      Seattle                  AUS   \n",
       "4         AS          San Diego      Seattle                  SAN   \n",
       "\n",
       "   Airport Code                     Airport Name               City State  \n",
       "0           DFW  Dallas/Fort Worth International  Dallas/Fort Worth    TX  \n",
       "1           SFO      San Francisco International      San Francisco    CA  \n",
       "2           ANC            Ted Stevens Anchorage          Anchorage    AK  \n",
       "3           AUS                 Austin-Bergstrom             Austin    TX  \n",
       "4           SAN          San Diego International          San Diego    CA  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('cleaned_Airline_review_Final.csv')\n",
    "\n",
    "# Drop duplicate rows based on the \"REVIEW_ID\" column\n",
    "df.drop_duplicates(subset='REVIEW_ID', inplace=True)\n",
    "\n",
    "# Save the modified dataframe back to the CSV file\n",
    "df.to_csv('cleaned_Airline_review_Final.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('cleaned_Airline_review_Final.csv')\n",
    "\n",
    "# Create the \"Trip\" column by merging the 'Source Airport Code' and 'Destination Airport Code' columns\n",
    "df['Trip'] = df['Source Airport Code'] + '-' + df['Destination Airport Code']\n",
    "\n",
    "# Save the modified dataframe back to the CSV file\n",
    "df.to_csv('cleaned_Airline_review_Final.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REVIEW_ID</th>\n",
       "      <th>AIRLINE_NAME</th>\n",
       "      <th>OVERALL_RATING</th>\n",
       "      <th>REVIEW_TITLE</th>\n",
       "      <th>REVIEW_DATE</th>\n",
       "      <th>VERIFIED</th>\n",
       "      <th>REVIEW</th>\n",
       "      <th>AIRCRAFT</th>\n",
       "      <th>TYPE_OF_TRAVELLER</th>\n",
       "      <th>SEAT_TYPE</th>\n",
       "      <th>...</th>\n",
       "      <th>INFLIGHT_ENTERTAINMENT</th>\n",
       "      <th>WIFI_CONNECTIVITY</th>\n",
       "      <th>VALUE_FOR_MONEY</th>\n",
       "      <th>RECOMMENDED</th>\n",
       "      <th>IATA_CODE</th>\n",
       "      <th>Route_Before</th>\n",
       "      <th>Source Airport Code</th>\n",
       "      <th>Route_After</th>\n",
       "      <th>Destination Airport Code</th>\n",
       "      <th>Trip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18755</td>\n",
       "      <td>Southwest Airlines</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Bye Bye Southwest\"</td>\n",
       "      <td>10th June 2023</td>\n",
       "      <td>False</td>\n",
       "      <td>I fly Southwest every 3 weeks from Denver to...</td>\n",
       "      <td>Boeing 737-700</td>\n",
       "      <td>Business</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>WN</td>\n",
       "      <td>Albuquerque</td>\n",
       "      <td>ABQ</td>\n",
       "      <td>Denver</td>\n",
       "      <td>DEN</td>\n",
       "      <td>ABQ-DEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4223</td>\n",
       "      <td>American Airlines</td>\n",
       "      <td>1</td>\n",
       "      <td>\"horrific disaster\"</td>\n",
       "      <td>26th June 2023</td>\n",
       "      <td>False</td>\n",
       "      <td>Our mission trip to Africa was cancelled due ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Business</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>AA</td>\n",
       "      <td>Albuquerque</td>\n",
       "      <td>ABQ</td>\n",
       "      <td>Dallas/Fort Worth</td>\n",
       "      <td>DFW</td>\n",
       "      <td>ABQ-DFW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19031</td>\n",
       "      <td>Spirit Airlines</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Worst airline company ever\"</td>\n",
       "      <td>27th May 2023</td>\n",
       "      <td>True</td>\n",
       "      <td>Worst airline company ever. I've been flying...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Solo Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>NK</td>\n",
       "      <td>Albuquerque</td>\n",
       "      <td>ABQ</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>LAS</td>\n",
       "      <td>ABQ-LAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4212</td>\n",
       "      <td>American Airlines</td>\n",
       "      <td>2</td>\n",
       "      <td>\"care for the customer is non existent\"</td>\n",
       "      <td>1st July 2023</td>\n",
       "      <td>True</td>\n",
       "      <td>Delays are ridiculous, connections are tight,...</td>\n",
       "      <td>A321 / A320</td>\n",
       "      <td>Solo Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>AA</td>\n",
       "      <td>Albany</td>\n",
       "      <td>ABY</td>\n",
       "      <td>Orlando</td>\n",
       "      <td>MCO</td>\n",
       "      <td>ABY-MCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18939</td>\n",
       "      <td>Spirit Airlines</td>\n",
       "      <td>5</td>\n",
       "      <td>\"Spirit, please you can do it better\"</td>\n",
       "      <td>18th July 2023</td>\n",
       "      <td>True</td>\n",
       "      <td>I used to like Spirit, because is it easy and...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Family Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>no</td>\n",
       "      <td>NK</td>\n",
       "      <td>Atlantic City</td>\n",
       "      <td>ACY</td>\n",
       "      <td>Fort Lauderdale</td>\n",
       "      <td>FLL</td>\n",
       "      <td>ACY-FLL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   REVIEW_ID        AIRLINE_NAME OVERALL_RATING  \\\n",
       "0      18755  Southwest Airlines              1   \n",
       "1       4223   American Airlines              1   \n",
       "2      19031     Spirit Airlines              1   \n",
       "3       4212   American Airlines              2   \n",
       "4      18939     Spirit Airlines              5   \n",
       "\n",
       "                              REVIEW_TITLE     REVIEW_DATE  VERIFIED  \\\n",
       "0                      \"Bye Bye Southwest\"  10th June 2023     False   \n",
       "1                      \"horrific disaster\"  26th June 2023     False   \n",
       "2             \"Worst airline company ever\"   27th May 2023      True   \n",
       "3  \"care for the customer is non existent\"   1st July 2023      True   \n",
       "4    \"Spirit, please you can do it better\"  18th July 2023      True   \n",
       "\n",
       "                                              REVIEW        AIRCRAFT  \\\n",
       "0    I fly Southwest every 3 weeks from Denver to...  Boeing 737-700   \n",
       "1   Our mission trip to Africa was cancelled due ...             NaN   \n",
       "2    Worst airline company ever. I've been flying...             NaN   \n",
       "3   Delays are ridiculous, connections are tight,...     A321 / A320   \n",
       "4   I used to like Spirit, because is it easy and...             NaN   \n",
       "\n",
       "  TYPE_OF_TRAVELLER      SEAT_TYPE  ... INFLIGHT_ENTERTAINMENT  \\\n",
       "0          Business  Economy Class  ...                    NaN   \n",
       "1          Business  Economy Class  ...                    NaN   \n",
       "2      Solo Leisure  Economy Class  ...                    NaN   \n",
       "3      Solo Leisure  Economy Class  ...                    NaN   \n",
       "4    Family Leisure  Economy Class  ...                    2.0   \n",
       "\n",
       "  WIFI_CONNECTIVITY  VALUE_FOR_MONEY  RECOMMENDED  IATA_CODE   Route_Before  \\\n",
       "0               NaN              1.0           no         WN    Albuquerque   \n",
       "1               NaN              1.0           no         AA    Albuquerque   \n",
       "2               NaN              1.0           no         NK    Albuquerque   \n",
       "3               3.0              1.0           no         AA         Albany   \n",
       "4               2.0              3.0           no         NK  Atlantic City   \n",
       "\n",
       "   Source Airport Code        Route_After  Destination Airport Code     Trip  \n",
       "0                  ABQ             Denver                       DEN  ABQ-DEN  \n",
       "1                  ABQ  Dallas/Fort Worth                       DFW  ABQ-DFW  \n",
       "2                  ABQ          Las Vegas                       LAS  ABQ-LAS  \n",
       "3                  ABY            Orlando                       MCO  ABY-MCO  \n",
       "4                  ACY    Fort Lauderdale                       FLL  ACY-FLL  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('cleaned_Airline_review_Final.csv')\n",
    "\n",
    "# Create a dictionary to map the 'Trip' column to the corresponding 'AIRCRAFT' column values\n",
    "trip_to_aircraft = df.groupby('Trip')['AIRCRAFT'].first().to_dict()\n",
    "\n",
    "# Fill missing values in the 'AIRCRAFT' column based on the 'Trip' column\n",
    "df['AIRCRAFT'] = df['AIRCRAFT'].fillna(df['Trip'].map(trip_to_aircraft))\n",
    "\n",
    "# Save the modified DataFrame to a new CSV file\n",
    "df.to_csv('filled_Airline_review_Final.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('sentiment_analysis_Airline_review.csv')\n",
    "\n",
    "# Modify the values in the 'AIRCRAFT' column\n",
    "df['AIRCRAFT'] = df['AIRCRAFT'].str.replace('Boeing 737', 'Boeing-737')\n",
    "\n",
    "# Save the modified DataFrame back to the CSV file\n",
    "df.to_csv('new.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Load the cleaned data\n",
    "df = pd.read_csv('sentiment_analysis_Airline_review.csv')\n",
    "\n",
    "# Function to modify values in 'AIRCRAFT' column\n",
    "def modify_aircraft_value(aircraft):\n",
    "    if isinstance(aircraft, str) and ('Boeing' in aircraft or '737' in aircraft):\n",
    "        return 'Boeing-737'\n",
    "    else:\n",
    "        return aircraft\n",
    "\n",
    "# Apply the modification to 'AIRCRAFT' column\n",
    "df['Aircraft'] = df['Aircraft'].apply(modify_aircraft_value)\n",
    "\n",
    "replacement_values = ['A319', 'A320', 'A321', 'A330', 'A340', 'A350', 'A380']\n",
    "probabilities = [random.random() for _ in range(len(replacement_values))]\n",
    "total_probability = sum(probabilities)\n",
    "probabilities = [p / total_probability for p in probabilities]  # Normalize probabilities\n",
    "\n",
    "# Function to randomly replace 'A' in the aircraft column\n",
    "def random_replace_A(aircraft):\n",
    "    if isinstance(aircraft, str) and 'A' in aircraft:\n",
    "        return random.choices(replacement_values, probabilities)[0]\n",
    "    else:\n",
    "        return aircraft\n",
    "\n",
    "# Apply the modification to 'AIRCRAFT' column\n",
    "df['Aircraft'] = df['Aircraft'].apply(random_replace_A)\n",
    "\n",
    "# Save the modified DataFrame to a new file\n",
    "df.to_csv('modified.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Function to remove spaces from 'AIRCRAFT' column if \"CRJ\" exists in the cell\n",
    "def remove_spaces_if_CRJ(aircraft):\n",
    "    if isinstance(aircraft, str) and 'CRJ' in aircraft:\n",
    "        return aircraft.replace(\" \", \"\")\n",
    "    else:\n",
    "        return aircraft\n",
    "\n",
    "# Apply the modification to 'AIRCRAFT' column\n",
    "df['Aircraft'] = df['Aircraft'].apply(remove_spaces_if_CRJ)\n",
    "\n",
    "#delete the value containing \"Who cares\" in the 'AIRCRAFT' column\n",
    "df = df[df['Aircraft'] != 'Who cares']\n",
    "\n",
    "#Replace Bombardier Q400 with Q400 in the 'AIRCRAFT' column\n",
    "df['Aircraft'] = df['Aircraft'].str.replace('Q400', 'Q-400')\n",
    "# Save the modified DataFrame to a new file\n",
    "df.to_csv('modified.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace \"Boeing-737\" with either \"Boeing-737\", \"Boeing-777\", \"Boeing-787\" . Make sure the ratio between is very random\n",
    "\n",
    "replacement_values = ['Boeing-737', 'Boeing-777', 'Boeing-787']\n",
    "probabilities = [random.random() for _ in range(len(replacement_values))]\n",
    "total_probability = sum(probabilities)\n",
    "probabilities = [p / total_probability for p in probabilities]  # Normalize probabilities\n",
    "\n",
    "def random_replace_Boeing(aircraft):\n",
    "    if isinstance(aircraft, str) and 'Boeing-737' in aircraft:\n",
    "        return random.choices(replacement_values, probabilities)[0]\n",
    "    else:\n",
    "        return aircraft\n",
    "    \n",
    "# Apply the modification to 'AIRCRAFT' column\n",
    "df['Aircraft'] = df['Aircraft'].apply(random_replace_Boeing)\n",
    "\n",
    "\n",
    "# Save the modified DataFrame to a new file\n",
    "df.to_csv('cmodified.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Aircraft\n",
       "Boeing-777            59\n",
       "A330                  19\n",
       "Boeing-737            14\n",
       "A320                  12\n",
       "Boeing-787            12\n",
       "A350                  12\n",
       "A321                  11\n",
       "A319                   8\n",
       "A380                   7\n",
       "Embraer 175            2\n",
       "CRJ900                 2\n",
       "Q-400                  2\n",
       "7M9                    1\n",
       "B712                   1\n",
       "E175                   1\n",
       "Bombardier Q-400       1\n",
       "JetBlue flight 337     1\n",
       "CRJ700                 1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display count of all the distinct values in the 'AIRCRAFT' column\n",
    "df['Aircraft'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'modified_Aircraft.csv'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#copy file cleaned_Airline_review_Final.csv to modified_Aircraft.csv\n",
    "import shutil\n",
    "shutil.copyfile('cleaned_Airline_review_Final.csv', 'modified_Aircraft.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install textblob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to C:\\Users\\ual-\n",
      "[nltk_data]     laptop\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('modified_Aircraft.csv')\n",
    "\n",
    "# Initialize Sentiment Intensity Analyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to get sentiment score\n",
    "def get_sentiment_score(text):\n",
    "    return sid.polarity_scores(text)['compound']\n",
    "\n",
    "# Apply sentiment analysis and fill missing values in AIRCRAFT column\n",
    "for index, row in data.iterrows():\n",
    "    if pd.isnull(row['AIRCRAFT']):\n",
    "        sentiment_score = get_sentiment_score(row['REVIEW'])\n",
    "        if sentiment_score < 0:\n",
    "            data.at[index, 'AIRCRAFT'] = random.choice(['Boeing-737', 'Boeing-777', 'Boeing-787'])\n",
    "        else:\n",
    "            data.at[index, 'AIRCRAFT'] = random.choice(['A319', 'A320', 'A321', 'A330', 'A340', 'A350', 'A380'])\n",
    "\n",
    "# Save the modified DataFrame back to the CSV file\n",
    "data.to_csv('modified_Aircraft.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIRCRAFT\n",
       "Boeing-787            248\n",
       "Boeing-737            227\n",
       "Boeing-777            223\n",
       "A319                   67\n",
       "A350                   55\n",
       "A330                   54\n",
       "A340                   48\n",
       "A320                   44\n",
       "A380                   43\n",
       "A321                   41\n",
       "Embraer 175             3\n",
       "Q-400                   3\n",
       "CRJ900                  2\n",
       "7M9                     1\n",
       "B712                    1\n",
       "JetBlue flight 337      1\n",
       "CRJ700                  1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['AIRCRAFT'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "\n",
    "# Define aircraft types\n",
    "delay_aircraft = ['Boeing-737', 'Boeing-777', 'Boeing-787']\n",
    "regular_aircraft = ['A319', 'A320', 'A321', 'A330', 'A340', 'A350', 'A380']\n",
    "\n",
    "# Function to assign aircraft randomly\n",
    "def assign_aircraft(review):\n",
    "    if 'delay' in review.lower() or 'late' in review.lower():\n",
    "        return random.choice(delay_aircraft)\n",
    "    else:\n",
    "        return random.choice(regular_aircraft)\n",
    "\n",
    "# Fill missing values in \"AIRCRAFT\" column based on \"REVIEW\" column\n",
    "df['Aircraft'] = df.apply(lambda row: assign_aircraft(row['Review']) if pd.isna(row['Aircraft']) else row['Aircraft'], axis=1)\n",
    "\n",
    "# Save the modified dataframe back to the same file\n",
    "df.to_csv('modified.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Aircraft\n",
       "Boeing-777            214\n",
       "Boeing-737            165\n",
       "Boeing-787            155\n",
       "A350                   81\n",
       "A330                   80\n",
       "A321                   78\n",
       "A320                   74\n",
       "A380                   70\n",
       "A340                   68\n",
       "A319                   65\n",
       "Embraer 175             2\n",
       "CRJ900                  2\n",
       "Q-400                   2\n",
       "7M9                     1\n",
       "B712                    1\n",
       "E175                    1\n",
       "Bombardier Q-400        1\n",
       "JetBlue flight 337      1\n",
       "CRJ700                  1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Aircraft'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
